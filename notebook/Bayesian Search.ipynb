{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time  # Just to compare fit times\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    return {'r2': round(r2, 4), 'MAE': round(mean_absolute_error, 4), 'MSE': round(mse, 4), 'RMSE': round(np.sqrt(mse), 4), \"explained_variance\": round(explained_variance, 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/dev/Desktop/Work/uncoverml/venv/bin/ray start --head --port=6379 --num-cpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/dev/Desktop/Work/uncoverml/venv/bin/ray --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/dev/Desktop/Work/uncoverml/venv/bin/ray stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-07 22:39:18,378\tINFO services.py:1171 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.11.161',\n",
       " 'raylet_ip_address': '192.168.11.161',\n",
       " 'redis_address': '192.168.11.161:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-02-07_22-39-17_925678_54681/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-02-07_22-39-17_925678_54681/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-02-07_22-39-17_925678_54681',\n",
       " 'metrics_export_port': 61559,\n",
       " 'node_id': '2af2ee503a4ebfe84fdd8c6431d42412fb05b62b'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=20, num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.1/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3/20 CPUs, 3/4 GPUs, 0.0/73.63 GiB heap, 0.0/24.51 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/dev/ray_results/_Trainable_2021-02-08_05-44-38<br>Number of trials: 262/300 (1 PENDING, 3 RUNNING, 258 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the csv file created\n",
    "\n",
    "input_files = [\n",
    "    Path(\"../data/formated_dataset.csv\"),\n",
    "    Path(\"../data/scaler_df.csv\"),\n",
    "    Path(\"../data/quantile_df.csv\"),\n",
    "]\n",
    "\n",
    "\n",
    "features_to_use = [\"target\",\"Grav_lane_clip\",\"clim_PTA_albers\",\"be-30y-85m-avg-ND-RED-BLUE.filled.lzw.nodata\",\"3dem_mag1_fin\",\"ceno_euc_aust1\",\"be-30y-85m-avg-ND-SWIR1-NIR.filled.lzw.nodata\",\"Thorium_2016\",\"dem_fill\",\"relief_elev_focalrange1000m_3s\",\"LATITUDE_GRID1_clip\",\"LOC_distance_to_coast\",\"clim_EPA_albers\",\"be-30y-85m-avg-ND-SWIR1-SWIR2.filled.lzw.nodata\",\"LONGITUDE_GRID1_clip\",\"si_geol1\",\"3dem_mag2\",\"clim_WDA_albers\",\"Dose_2016\",\"Clim_Prescott_LindaGregory\",\"Potassium_2016\",\"mrvbf_9\",\"Rad2016K_Th\",\"be-30y-85m-avg-ND-NIR-GREEN.filled.lzw.nodata\",\"clim_RSM_albers\",\"3dem_mag0.fin\",\"s2-dpca-85m_1\",\"water-85m_3\",\"saga_wetSM_85_reprojected\"]\n",
    "\n",
    "parameters = {\n",
    "    \"objective\": [\"reg:squarederror\"],\n",
    "    \"gamma\":[0],\n",
    "    \"eval_metric\": [\"rmse\", \"mae\",\"logloss\",\"auc\"],\n",
    "    \"n_estimators\":[500, 700],\n",
    "    \"max_depth\":[3, 15],\n",
    "    \"subsample\":[0.8, 1],\n",
    "    \"min_child_weight\":[10, 20],\n",
    "    \"learning_rate\":[0.01, 0.2],\n",
    "    \"colsample_bytree\":[0.5,1]\n",
    "}\n",
    "\n",
    "model=XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist',n_jobs=-1)\n",
    "\n",
    "xgb_tune_search = TuneSearchCV(\n",
    "    model,\n",
    "    parameters,\n",
    "\n",
    "    search_optimization=\"bayesian\",\n",
    "    n_jobs=-1,\n",
    "    n_trials=300,\n",
    "    early_stopping=False,\n",
    "\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    loggers=[\"csv\"],\n",
    "    use_gpu=True\n",
    ")\n",
    "\n",
    "for input_file in input_files:\n",
    "\n",
    "    print(\"Input file: \",input_file)\n",
    "    df = pd.read_csv(input_file).astype('float32')\n",
    "    df = df[~df.isin([np.nan, np.inf, -np.inf,-9999.0]).any(1)]\n",
    "    df = df[features_to_use]\n",
    "    y_train = df['target']\n",
    "    X_train = df.drop(\"target\",axis=1)\n",
    "    \n",
    "    start = time.time()\n",
    "    xgb_tune_search.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Tune Fit Time:\", end - start)  \n",
    "    \n",
    "    fileObj = open('xgb_tune_search'+input_file.stem+'.pkl', 'wb')\n",
    "    pickle.dump(xgb_tune_search,fileObj)\n",
    "    fileObj.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file:  ../data/formated_dataset.csv\n",
      "Input oos file:  ../data/formated_oos_dataset.csv\n",
      "Training results: {'r2': 0.9679, 'MAE': 0.0408, 'MSE': 0.0056, 'RMSE': 0.075, 'explained_variance': 0.9679}\n",
      "OOS results: {'r2': 0.6754, 'MAE': 0.6638, 'MSE': 1.5891, 'RMSE': 1.2606, 'explained_variance': 0.6888}\n",
      "\n",
      "\n",
      "Input file:  ../data/scaler_df.csv\n",
      "Input oos file:  ../data/scaler_oos_df.csv\n",
      "Training results: {'r2': 1.0, 'MAE': 0.0015, 'MSE': 0.0, 'RMSE': 0.0021, 'explained_variance': 1.0}\n",
      "OOS results: {'r2': 1.0, 'MAE': 0.0015, 'MSE': 0.0, 'RMSE': 0.0021, 'explained_variance': 1.0}\n",
      "\n",
      "\n",
      "Input file:  ../data/quantile_df.csv\n",
      "Input oos file:  ../data/quantile_oos_df.csv\n",
      "Training results: {'r2': 0.9326, 'MAE': 0.0551, 'MSE': 0.0056, 'RMSE': 0.0751, 'explained_variance': 0.9326}\n",
      "OOS results: {'r2': 0.8552, 'MAE': 0.106, 'MSE': 0.023, 'RMSE': 0.1515, 'explained_variance': 0.8703}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_files = [\n",
    "    (Path(\"../data/formated_dataset.csv\"),Path(\"../data/formated_oos_dataset.csv\")),\n",
    "    (Path(\"../data/scaler_df.csv\"),Path(\"../data/scaler_oos_df.csv\")),\n",
    "    (Path(\"../data/quantile_df.csv\"),Path(\"../data/quantile_oos_df.csv\"))\n",
    "]\n",
    "\n",
    "\n",
    "features_to_use = [\"target\",\"Grav_lane_clip\",\"clim_PTA_albers\",\"be-30y-85m-avg-ND-RED-BLUE.filled.lzw.nodata\",\"3dem_mag1_fin\",\"ceno_euc_aust1\",\"be-30y-85m-avg-ND-SWIR1-NIR.filled.lzw.nodata\",\"Thorium_2016\",\"dem_fill\",\"relief_elev_focalrange1000m_3s\",\"LATITUDE_GRID1_clip\",\"LOC_distance_to_coast\",\"clim_EPA_albers\",\"be-30y-85m-avg-ND-SWIR1-SWIR2.filled.lzw.nodata\",\"LONGITUDE_GRID1_clip\",\"si_geol1\",\"3dem_mag2\",\"clim_WDA_albers\",\"Dose_2016\",\"Clim_Prescott_LindaGregory\",\"Potassium_2016\",\"mrvbf_9\",\"Rad2016K_Th\",\"be-30y-85m-avg-ND-NIR-GREEN.filled.lzw.nodata\",\"clim_RSM_albers\",\"3dem_mag0.fin\",\"s2-dpca-85m_1\",\"water-85m_3\",\"saga_wetSM_85_reprojected\"]\n",
    "\n",
    "for input_file,input_oos_file in input_files:\n",
    "\n",
    "    print(\"Input file: \",input_file)\n",
    "    df = pd.read_csv(input_file).astype('float32')\n",
    "    df = df[~df.isin([np.nan, np.inf, -np.inf,-9999.0]).any(1)]\n",
    "    df = df[features_to_use]\n",
    "    y_train = df['target']\n",
    "    X_train = df.drop(\"target\",axis=1)\n",
    "    \n",
    "    print(\"Input oos file: \",input_oos_file)\n",
    "    df = pd.read_csv(input_oos_file).astype('float32')\n",
    "    df = df[~df.isin([np.nan, np.inf, -np.inf,-9999.0]).any(1)]\n",
    "    df = df[features_to_use]\n",
    "    y_oos = df['target']\n",
    "    X_oos = df.drop(\"target\",axis=1)\n",
    "    \n",
    "\n",
    "    with open('xgb_tune_search'+input_file.stem+'.pkl', \"rb\") as f:\n",
    "        xgb_tune_search = pickle.load(f)\n",
    "    best_model = xgb_tune_search.best_estimator_\n",
    "\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    results_oss = regression_results(y_train, y_train_pred)\n",
    "    print(\"Training results:\",results_oss)\n",
    "\n",
    "    y_oos_pred = best_model.predict(X_oos)\n",
    "    results_oss = regression_results(y_oos, y_oos_pred)\n",
    "    print(\"OOS results:\",results_oss)\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read results\n",
    "import pickle\n",
    "\n",
    "with open(\"xgb_tune_search.pkl\", \"rb\") as f:\n",
    "    xgb_tune_search = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8143159659128333,\n",
       "             eval_metric='auc', gamma=0, gpu_id=0, importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.10635403959720964,\n",
       "             max_delta_step=0, max_depth=11, min_child_weight=16, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=660, n_jobs=-1,\n",
       "             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=0.85619873071933,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tune_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_tune_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results:  {'r2': 0.9092, 'MAE': 0.0609, 'MSE': 0.0076, 'RMSE': 0.0874, 'explained_variance': 0.9092}\n",
      "XGBOOST HyperParameter Tuning  0.003015621503194173 minutes ---\n"
     ]
    }
   ],
   "source": [
    "## Fit with cross validation\n",
    "start_time = time.time()\n",
    "# xgb_tune_search.best_estimator_.fit(X_test, y_test)   \n",
    "y_pred = xgb_tune_search.best_estimator_.predict(X_test)\n",
    "duration = (time.time() - start_time)/60       \n",
    "print(\"results: \",regression_results(y_test, y_pred))\n",
    "print(\"XGBOOST HyperParameter Tuning  %s minutes ---\" % + duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOS Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file:  ../data/formated_dataset.csv\n",
      "Input oos file:  ../data/formated_oos_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# read the csv file created\n",
    "input_files = [\n",
    "    Path(\"../data/formated_dataset.csv\"),\n",
    "    Path(\"../data/scaler_df.csv\"),\n",
    "    Path(\"../data/quantile_df.csv\")\n",
    "]\n",
    "\n",
    "input_oos_files = [\n",
    "    Path(\"../data/formated_oos_dataset.csv\"),\n",
    "    Path(\"../data/scaler_oos_df.csv\"),\n",
    "    Path(\"../data/quantile_oos_df.csv\")\n",
    "]\n",
    "\n",
    "features_to_use = [\"target\",\"Grav_lane_clip\",\"clim_PTA_albers\",\"be-30y-85m-avg-ND-RED-BLUE.filled.lzw.nodata\",\"3dem_mag1_fin\",\"ceno_euc_aust1\",\"be-30y-85m-avg-ND-SWIR1-NIR.filled.lzw.nodata\",\"Thorium_2016\",\"dem_fill\",\"relief_elev_focalrange1000m_3s\",\"LATITUDE_GRID1_clip\",\"LOC_distance_to_coast\",\"clim_EPA_albers\",\"be-30y-85m-avg-ND-SWIR1-SWIR2.filled.lzw.nodata\",\"LONGITUDE_GRID1_clip\",\"si_geol1\",\"3dem_mag2\",\"clim_WDA_albers\",\"Dose_2016\",\"Clim_Prescott_LindaGregory\",\"Potassium_2016\",\"mrvbf_9\",\"Rad2016K_Th\",\"be-30y-85m-avg-ND-NIR-GREEN.filled.lzw.nodata\",\"clim_RSM_albers\",\"3dem_mag0.fin\",\"s2-dpca-85m_1\",\"water-85m_3\",\"saga_wetSM_85_reprojected\"]\n",
    "\n",
    "input_file = input_files[0]\n",
    "print(\"Input file: \",input_file)\n",
    "df = pd.read_csv(input_file).astype('float32')\n",
    "df = df[~df.isin([np.nan, np.inf, -np.inf,-9999.0]).any(1)]\n",
    "df = df[features_to_use]\n",
    "y = df['target']\n",
    "X = df.drop(\"target\",axis=1)\n",
    "\n",
    "input_oos_file = input_oos_files[0]\n",
    "print(\"Input oos file: \",input_oos_file)\n",
    "df = pd.read_csv(input_oos_file).astype('float32')\n",
    "df = df[~df.isin([np.nan, np.inf, -np.inf,-9999.0]).any(1)]\n",
    "df = df[features_to_use]\n",
    "y_oos = df['target']\n",
    "X_oos = df.drop(\"target\",axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS results:\n",
      "{'r2': 0.7721, 'MAE': 0.5843, 'MSE': 1.1158, 'RMSE': 1.0563, 'explained_variance': 0.7766}\n"
     ]
    }
   ],
   "source": [
    "# OOS sample dataset\n",
    "# need to itrate over all the models that are selected!!\n",
    "best_model = xgb_tune_search.best_estimator_\n",
    "y_pred = best_model.predict(X_oos)\n",
    "results_oss = regression_results(y_oos, y_pred)\n",
    "print(\"OOS results:\",results_oss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results:\n",
      "{'r2': 0.9831, 'MAE': 0.0259, 'MSE': 0.003, 'RMSE': 0.0544, 'explained_variance': 0.9831}\n"
     ]
    }
   ],
   "source": [
    "# OOS sample dataset\n",
    "# need to itrate over all the models that are selected!!\n",
    "best_model = xgb_tune_search.best_estimator_\n",
    "y_pred = best_model.predict(X)\n",
    "results_oss = regression_results(y, y_pred)\n",
    "print(\"Training results:\")\n",
    "print(results_oss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
