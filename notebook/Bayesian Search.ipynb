{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time  # Just to compare fit times\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mLocal node IP\u001b[39m: \u001b[1m10.6.54.24\u001b[22m\n",
      "2021-01-20 15:03:20,238\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://localhost:8265\u001b[39m\u001b[22m\n",
      "\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\u001b[32mRay runtime started.\u001b[39m\n",
      "\u001b[32m--------------------\u001b[39m\n",
      "\n",
      "\u001b[36mNext steps\u001b[39m\n",
      "  To connect to this Ray runtime from another node, run\n",
      "  \u001b[1m  ray start --address='10.6.54.24:6379' --redis-password='5241590000000000'\u001b[22m\n",
      "  \n",
      "  Alternatively, use the following Python code:\n",
      "    \u001b[31mimport\u001b[39m\u001b[26m ray\n",
      "    ray\u001b[31m.\u001b[39m\u001b[26minit(address\u001b[31m=\u001b[39m\u001b[26m\u001b[33m'auto'\u001b[39m\u001b[26m, _redis_password\u001b[31m=\u001b[39m\u001b[26m\u001b[33m'5241590000000000'\u001b[39m\u001b[26m)\n",
      "  \n",
      "  \u001b[4mIf connection fails, check your firewall settings and network configuration.\u001b[24m\n",
      "  \n",
      "  To terminate the Ray runtime, run\n",
      "  \u001b[1m  ray stop\u001b[22m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!~/.local/bin/ray start --head --port=6379 --num-cpus=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray, version 1.0.1.post1\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !~/.local/bin/ray --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ray.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find any active Ray processes.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!~/.local/bin/ray stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-20 15:03:29,523\tINFO worker.py:651 -- Connecting to existing Ray cluster at address: 10.6.54.24:6379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.6.54.24',\n",
       " 'raylet_ip_address': '10.6.54.24',\n",
       " 'redis_address': '10.6.54.24:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-01-20_15-03-19_741961_43497/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-01-20_15-03-19_741961_43497/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-01-20_15-03-19_741961_43497',\n",
       " 'metrics_export_port': 63888,\n",
       " 'node_id': 'd3b7c44a1054120eddd1d4322b200836fa7fefc7'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto', _redis_password='5241590000000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file created\n",
    "input_dataset = Path(\"../data/quantile_df.csv\")\n",
    "df = pd.read_csv(input_dataset)\n",
    "df = df.drop([\"x\",\"y\"],axis=1)\n",
    "\n",
    "\n",
    "y = df['target'] \n",
    "X = df.drop(\"target\",axis=1)\n",
    "\n",
    "# X, y = train[:, 1:], train[:, :1]\n",
    "# y = y.ravel()\n",
    "\n",
    "# Set training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.9/188.6 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 1.000: None<br>Resources requested: 38.0/40 CPUs, 0/0 GPUs, 0.0/120.8 GiB heap, 0.0/38.48 GiB objects<br>Result logdir: /home/547/sg4953/ray_results/_Trainable_2021-01-20_15-05-46<br>Number of trials: 38/200 (38 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status  </th><th>loc  </th><th>eval_metric  </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  n_estimators</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_Trainable_c602613c</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       6.09683 </td><td style=\"text-align: right;\">         23</td><td style=\"text-align: right;\">            50</td></tr>\n",
       "<tr><td>_Trainable_c6266eba</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       0.508988</td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">            55</td></tr>\n",
       "<tr><td>_Trainable_c649ab00</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       2.01223 </td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">            47</td></tr>\n",
       "<tr><td>_Trainable_c6620e7a</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       9.06254 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">            47</td></tr>\n",
       "<tr><td>_Trainable_c6774556</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       9.03975 </td><td style=\"text-align: right;\">         24</td><td style=\"text-align: right;\">            29</td></tr>\n",
       "<tr><td>_Trainable_c6869dee</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       4.08791 </td><td style=\"text-align: right;\">         19</td><td style=\"text-align: right;\">            89</td></tr>\n",
       "<tr><td>_Trainable_c69c1598</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       9.30218 </td><td style=\"text-align: right;\">         16</td><td style=\"text-align: right;\">            94</td></tr>\n",
       "<tr><td>_Trainable_c6af3542</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       2.63628 </td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">            55</td></tr>\n",
       "<tr><td>_Trainable_c6c005ca</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       4.50979 </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">            92</td></tr>\n",
       "<tr><td>_Trainable_c6ce362c</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       7.87707 </td><td style=\"text-align: right;\">         30</td><td style=\"text-align: right;\">            16</td></tr>\n",
       "<tr><td>_Trainable_c6f713ee</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       4.28862 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">            96</td></tr>\n",
       "<tr><td>_Trainable_c717722e</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       1.19487 </td><td style=\"text-align: right;\">         30</td><td style=\"text-align: right;\">            33</td></tr>\n",
       "<tr><td>_Trainable_c73a8c32</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       8.8794  </td><td style=\"text-align: right;\">         23</td><td style=\"text-align: right;\">            30</td></tr>\n",
       "<tr><td>_Trainable_c74cc71c</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       0.960785</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">            60</td></tr>\n",
       "<tr><td>_Trainable_c76bff74</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       2.75967 </td><td style=\"text-align: right;\">         14</td><td style=\"text-align: right;\">            38</td></tr>\n",
       "<tr><td>_Trainable_c77b0992</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       6.25075 </td><td style=\"text-align: right;\">         18</td><td style=\"text-align: right;\">            29</td></tr>\n",
       "<tr><td>_Trainable_c7a4abf8</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       1.44306 </td><td style=\"text-align: right;\">         19</td><td style=\"text-align: right;\">            89</td></tr>\n",
       "<tr><td>_Trainable_c7c4e4d6</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       0.243631</td><td style=\"text-align: right;\">         15</td><td style=\"text-align: right;\">            28</td></tr>\n",
       "<tr><td>_Trainable_c7d13240</td><td>RUNNING </td><td>     </td><td>rmse         </td><td style=\"text-align: right;\">       3.77919 </td><td style=\"text-align: right;\">         12</td><td style=\"text-align: right;\">            27</td></tr>\n",
       "<tr><td>_Trainable_c7ddb272</td><td>RUNNING </td><td>     </td><td>logloss      </td><td style=\"text-align: right;\">       9.14509 </td><td style=\"text-align: right;\">         29</td><td style=\"text-align: right;\">            92</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 18 more trials not shown (18 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-20 15:09:44,925\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::_Trainable.train()\u001b[39m (pid=43920, ip=10.6.54.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "    return self._train()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in _train\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in <dictcomp>\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/base.py\", line 554, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "2021-01-20 15:15:15,016\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::_Trainable.train()\u001b[39m (pid=43689, ip=10.6.54.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "    return self._train()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in _train\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in <dictcomp>\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/base.py\", line 554, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "2021-01-20 15:15:35,105\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::_Trainable.train()\u001b[39m (pid=43794, ip=10.6.54.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "    return self._train()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in _train\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in <dictcomp>\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/base.py\", line 554, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "2021-01-20 15:17:26,757\tERROR worker.py:1037 -- Possible unhandled error from worker: \u001b[36mray::_Trainable.train()\u001b[39m (pid=43991, ip=10.6.54.24)\n",
      "  File \"python/ray/_raylet.pyx\", line 482, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 436, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/ray/tune/trainable.py\", line 336, in train\n",
      "    result = self.step()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "    return self._train()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in _train\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/tune_sklearn/_trainable.py\", line 205, in <dictcomp>\n",
      "    for name, score in self.scoring.items()\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 397, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/base.py\", line 554, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "parameters = {\n",
    "    \"eval_metric\": ['logloss', \"rmse\"],\n",
    "    \"n_estimators\": [10,100],\n",
    "    \"max_depth\": [5, 30],\n",
    "    \"learning_rate\": [0.1, 10]\n",
    "}\n",
    "\n",
    "xgb_tune_search = TuneSearchCV(\n",
    "    XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, alpha=10),\n",
    "    parameters,\n",
    "\n",
    "    search_optimization=\"bayesian\",\n",
    "#     max_iters=10,\n",
    "    n_jobs=40,\n",
    "    n_trials=200,\n",
    "    early_stopping=True,\n",
    "\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    loggers=[\"csv\"],\n",
    "\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "xgb_tune_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Tune Fit Time:\", end - start)\n",
    "y_pred = xgb_tune_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tune_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "import pickle\n",
    "\n",
    "fileObj = open('best_estimator_.pkl', 'wb')\n",
    "pickle.dump(xgb_tune_search.best_estimator_,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "import pickle\n",
    "\n",
    "fileObj = open('xgb_tune_search.pkl', 'wb')\n",
    "pickle.dump(xgb_tune_search,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    return {'r2': round(r2, 4), 'MAE': round(mean_absolute_error, 4), 'MSE': round(mse, 4), 'RMSE': round(np.sqrt(mse), 4), \"explained_variance\": round(explained_variance, 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###############################################\n",
    "# Import Machine Learning Assets\n",
    "###############################################\n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "###############################################\n",
    "# Import Miscellaneous Assets\n",
    "###############################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from pprint import pprint as pp\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "###############################################\n",
    "# Declare Global Variables\n",
    "###############################################\n",
    "CROSS_VALIDATION_PARAMS = dict(n_splits=5, shuffle=True, random_state=32)\n",
    "XGBOOST_REGRESSOR_PARAMS = dict(\n",
    "    learning_rate=0.2, n_estimators=200, subsample=0.8, colsample_bytree=0.8, \n",
    "    max_depth=10, n_jobs=-1\n",
    ")\n",
    "\n",
    "BAYESIAN_OPTIMIZATION_MAXIMIZE_PARAMS = dict(\n",
    "    init_points=1,  # init_points=20,\n",
    "    n_iter=2,  # n_iter=60,\n",
    "    acq='poi', xi=0.0\n",
    ")\n",
    "BAYESIAN_OPTIMIZATION_BOUNDARIES = dict(\n",
    "    max_depth=(5, 12.99),\n",
    "    gamma=(0.01, 5),\n",
    "    min_child_weight=(0, 6),\n",
    "    scale_pos_weight=(1.2, 5),\n",
    "    reg_alpha=(4.0, 10.0),\n",
    "    reg_lambda=(1.0, 10.0),\n",
    "    max_delta_step=(0, 5),\n",
    "    subsample=(0.5, 1.0),\n",
    "    colsample_bytree=(0.3, 1.0),\n",
    "    learning_rate=(0.0, 1.0)\n",
    ")\n",
    "BAYESIAN_OPTIMIZATION_INITIAL_SEARCH_POINTS = dict(\n",
    "    max_depth=[5, 10],\n",
    "    gamma=[0.1511, 3.8463],\n",
    "    min_child_weight=[2.4073, 4.9954],\n",
    "    scale_pos_weight=[2.2281, 4.0345],\n",
    "    reg_alpha=[8.0702, 9.0573],\n",
    "    reg_lambda=[2.0126, 3.5934],\n",
    "    max_delta_step=[1, 2],\n",
    "    subsample=[0.8, 0.8234],\n",
    "    colsample_bytree=[0.8, 0.7903],\n",
    "    learning_rate=[0.2, 0.1]\n",
    ")\n",
    "\n",
    "reserve_features = [\n",
    "    'rs1_x', 'rs1_y', 'rs2_x', 'rs2_y', 'rv1_x', 'rv1_y', 'rv2_x', 'rv2_y',\n",
    "    'total_reserve_dt_diff_mean', 'total_reserve_mean', 'total_reserve_sum'\n",
    "]\n",
    "\n",
    "BASE_ESTIMATOR = partial(XGBRegressor)\n",
    "# train_df, test_df = None, None\n",
    "# oof_predictions, test_predictions = None, None\n",
    "# train_input = None\n",
    "# best_round = None\n",
    "# target = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file created\n",
    "input_dataset = Path(\"../data/quantile_df.csv\")\n",
    "df = pd.read_csv(input_dataset)\n",
    "df = df.drop([\"x\",\"y\"],axis=1)\n",
    "\n",
    "\n",
    "y = df['target'] \n",
    "X = df.drop(\"target\",axis=1)\n",
    "\n",
    "# train_df, test_df = None, NOne\n",
    "# oof_predictions, test_predictions = None, None\n",
    "# train_input = None\n",
    "# best_round = None\n",
    "# target = None\n",
    "\n",
    "# X, y = train[:, 1:], train[:, :1]\n",
    "# y = y.ravel()\n",
    "\n",
    "# Set training and validation sets\n",
    "train_df, test_df, target, test_predictions = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_node(**kwargs):\n",
    "    # global train_df, test_df, train_input, oof, test_predictions, best_round, target\n",
    "    global train_df, target\n",
    "\n",
    "    ###############################################\n",
    "    # Unify Parameters\n",
    "    ###############################################\n",
    "    received_params = dict(dict(n_estimators=200,), **{_k: _v if _k not in ('max_depth') else int(_v) for _k, _v in kwargs.items()})\n",
    "    current_params = dict(XGBOOST_REGRESSOR_PARAMS, **received_params)\n",
    "\n",
    "    ###############################################\n",
    "    # Initialize Folds and Result Placeholders\n",
    "    ###############################################\n",
    "    folds = KFold(**CROSS_VALIDATION_PARAMS)\n",
    "    evaluation = np.zeros((current_params['n_estimators'], CROSS_VALIDATION_PARAMS['n_splits']))\n",
    "    oof_predictions = np.empty(len(train_df))\n",
    "    np.random.seed(32)\n",
    "\n",
    "    progress_bar = tqdm_notebook(\n",
    "        enumerate(folds.split(target, target)), \n",
    "        total=CROSS_VALIDATION_PARAMS['n_splits'], \n",
    "        leave=False\n",
    "    )\n",
    "    \n",
    "    ###############################################\n",
    "    # Begin Cross-Validation\n",
    "    ###############################################\n",
    "    for fold, (train_index, validation_index) in progress_bar:\n",
    "        train_input, validation_input = train_df.iloc[train_index], train_df.iloc[validation_index]\n",
    "        train_target, validation_target = target.iloc[train_index], target.iloc[validation_index]\n",
    "\n",
    "        ###############################################\n",
    "        # Initialize and Fit Model With Current Parameters\n",
    "        ###############################################\n",
    "        model = BASE_ESTIMATOR(**current_params)\n",
    "        eval_set = [(train_input, train_target), (validation_input, validation_target)]\n",
    "        model.fit(train_input, train_target, eval_set=eval_set, verbose=False)\n",
    "\n",
    "        ###############################################\n",
    "        # Find Best Round for Validation Set\n",
    "        ###############################################\n",
    "        evaluation[:, fold] = model.evals_result_[\"validation_1\"]['rmse']\n",
    "        best_round = np.argsort(evaluation[:, fold])[0]\n",
    "\n",
    "        progress_bar.set_description('Fold #{}:   {:.5f}'.format(\n",
    "            fold, evaluation[:, fold][best_round]\n",
    "        ), refresh=True)\n",
    "\n",
    "    ###############################################\n",
    "    # Compute Mean and Standard Deviation of RMSLE\n",
    "    ###############################################\n",
    "    mean_eval, std_eval = np.mean(evaluation, axis=1), np.std(evaluation, axis=1)\n",
    "    best_round = np.argsort(mean_eval)[0]\n",
    "    search_value = mean_eval[best_round]\n",
    "\n",
    "    ###############################################\n",
    "    # Update Best Score and Return Negative Value\n",
    "    # In order to minimize error, instead of maximizing accuracy\n",
    "    ###############################################\n",
    "    print(' Stopped After {} Epochs... Validation RMSLE: {:.6f} +- {:.6f}'.format(\n",
    "        best_round, search_value, std_eval[best_round]\n",
    "    ))\n",
    "\n",
    "    return -search_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesianOptimization' object has no attribute 'explore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9be4ba3ffde1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBAYESIAN_OPTIMIZATION_BOUNDARIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBAYESIAN_OPTIMIZATION_INITIAL_SEARCH_POINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesianOptimization' object has no attribute 'explore'"
     ]
    }
   ],
   "source": [
    "bayes_opt = BayesianOptimization(search_node, BAYESIAN_OPTIMIZATION_BOUNDARIES)\n",
    "bayes_opt.explore(BAYESIAN_OPTIMIZATION_INITIAL_SEARCH_POINTS)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    bayes_opt.maximize(**BAYESIAN_OPTIMIZATION_MAXIMIZE_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (4.228517846555483,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n",
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (4.228517846555483,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n",
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (4.228517846555483,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 4.229   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (7.231212485077365,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n",
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (7.231212485077365,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 7.231   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (7.231212485077365,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 88, in __call__\n",
      "    *args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 243, in _score\n",
      "    **self._kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 677, in r2_score\n",
      "    y_true, y_pred, multioutput)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 664, in check_array\n",
      "    allow_nan=force_all_finite == 'allow-nan')\n",
      "  File \"/home/547/sg4953/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 106, in _assert_all_finite\n",
      "    msg_dtype if msg_dtype is not None else X.dtype)\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1a368bce5740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer.maximize(\n\u001b[1;32m     24\u001b[0m     \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final result:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Finding argmax of the acquisition function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_vector_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             X, y = self._validate_data(X, y, multi_output=True, y_numeric=True,\n\u001b[0;32m--> 193\u001b[0;31m                                        ensure_2d=True, dtype=\"numeric\")\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             X, y = self._validate_data(X, y, multi_output=True, y_numeric=True,\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0;32m--> 824\u001b[0;31m                         ensure_2d=False, dtype=None)\n\u001b[0m\u001b[1;32m    825\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 664\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncoverml/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "input_dataset = Path(\"../data/quantile_df.csv\")\n",
    "df = pd.read_csv(input_dataset)\n",
    "df = df.drop([\"x\",\"y\"],axis=1)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "y = df['target'] \n",
    "X = df.drop(\"target\",axis=1)\n",
    "\n",
    "def get_estimator_score(learning_rate):    \n",
    "    estimator = XGBRegressor(objective='reg:squarederror', learning_rate=learning_rate)\n",
    "    scores = cross_val_score(estimator, X, y, scoring='r2', cv=3)\n",
    "    return scores.mean()\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=get_estimator_score,\n",
    "    pbounds={\"learning_rate\": (0.1, 10)},\n",
    "    random_state=1,\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=10\n",
    ")\n",
    "print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
